{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfa0d42c",
   "metadata": {},
   "source": [
    "# Known Problem:\n",
    "- **Unresolved**\n",
    "    1. how to solve for eigen vectors\n",
    "- **Partially Resolved**\n",
    "    1. Certain websites cause the error of, specified here: https://stackoverflow.com/questions/23013220/max-retries-exceeded-with-url-in-requests, which is a connection error. \n",
    "        - this appears to be windows specific as this was not a relevant issue when testing code in ubuntu 22.04, some forum reflect similar message\n",
    "        - FAILED SOLUTION: first response in that stackoverflow page, still kept the stuff bc it seemed like better QOL\n",
    "        - ATTEMPTED SOLUTION: used try and except. NOTE: this solution is not ideal as it does not resolve the issue, it just ignores it and moves on.\n",
    "- **Resolved**\n",
    "    1. The search \"what is a taylor series\" returns SSLCertVerification Error.\n",
    "        - this resolution does not consider the security of the websites being accessed, potentially use try except to have the request verify when possible and not break when cannot verify\n",
    "        - ATTEMPTED SOLUTION: used try except to use verify=False when ssl error occurs. Nested try except to ensure that both connection error and ssl error are handled.\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f736e92b-fcbc-4051-9b96-f1667b546b35",
   "metadata": {},
   "source": [
    "# Part 1: Data Acquisition & Preparation\n",
    "\n",
    "## Collecting & Preprocessing Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be0a22b4-8ee2-4ff9-afd6-ec408d9c905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import requests #send HTTP requests to web pages and retrieve their content\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from urllib.parse import urlparse, urljoin\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import http.client\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf32bf2a-fe64-40af-b413-4f2737bbc288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\William\n",
      "[nltk_data]     Zhang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\William\n",
      "[nltk_data]     Zhang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\William\n",
      "[nltk_data]     Zhang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ssl\n",
    "#ssl._create_default_https_context = ssl._create_unverified_context\n",
    "#uncomment if you cannot properly download punkt\n",
    "\n",
    "nltk.download('punkt')\n",
    "#ssl._create_default_https_context = ssl._create_default_https_context\n",
    "#uncomment if you cannot properly download punkt\n",
    "\n",
    "#remove filler words from an example column\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9215e926-9d63-4b94-9183-659fbc228d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying: https://www.ibm.com/topics/artificial-intelligence\n",
      "Trying: https://builtin.com/artificial-intelligence\n",
      "Trying: https://www.techtarget.com/searchenterpriseai/definition/AI-Artificial-Intelligence\n",
      "Trying: https://www.oracle.com/artificial-intelligence/what-is-ai/\n",
      "Trying: https://www.brookings.edu/articles/what-is-artificial-intelligence/\n",
      "Trying: https://www.britannica.com/technology/artificial-intelligence\n",
      "Trying: https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai\n",
      "Trying: https://www.sas.com/en_us/insights/analytics/what-is-artificial-intelligence.html\n",
      "Trying: https://en.wikipedia.org/wiki/Artificial_intelligence\n",
      "Trying: https://www.investopedia.com/terms/a/artificial-intelligence-ai.asp\n",
      "Trying: https://cloud.google.com/learn/what-is-artificial-intelligence\n",
      "Trying: https://www.zdnet.com/article/what-is-ai-heres-everything-you-need-to-know-about-artificial-intelligence/\n",
      "Trying: https://www.mygreatlearning.com/blog/what-is-artificial-intelligence/\n",
      "Trying: https://www.hpe.com/us/en/what-is/artificial-intelligence.html\n",
      "Trying: https://hai.stanford.edu/sites/default/files/2020-09/AI-Definitions-HAI.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: HTTPSConnectionPool(host='www.accenture.com', port=443): Max retries exceeded with url: /us-en/insights/artificial-intelligence-summary-index (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001FCA8B50640>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "SSL certificate verification failed for: https://www.accenture.com/us-en/insights/artificial-intelligence-summary-index\n",
      "Trying: https://www.techopedia.com/definition/190/artificial-intelligence-ai\n",
      "Trying: https://www.washingtonpost.com/technology/2023/05/07/ai-beginners-guide/\n",
      "Trying: https://www.gartner.com/en/topics/artificial-intelligence\n",
      "Trying: https://www.state.gov/artificial-intelligence/\n",
      "Trying: https://azure.microsoft.com/en-us/resources/cloud-computing-dictionary/artificial-intelligence-vs-machine-learning/\n",
      "Trying: https://www.simplilearn.com/tutorials/artificial-intelligence-tutorial/what-is-artificial-intelligence\n",
      "Trying: https://aws.amazon.com/machine-learning/what-is-ai/\n",
      "Trying: https://www.netapp.com/artificial-intelligence/what-is-artificial-intelligence/\n",
      "Trying: https://www.nist.gov/artificial-intelligence\n",
      "Trying: https://www.youtube.com/watch?v=ad79nYk2keg\n",
      "Trying: https://www.sap.com/products/artificial-intelligence/what-is-artificial-intelligence.html\n",
      "Trying: https://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/\n",
      "Error: HTTPSConnectionPool(host='sitn.hms.harvard.edu', port=443): Max retries exceeded with url: /flash/2017/history-artificial-intelligence/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001FCA8CBC7C0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "SSL certificate verification failed for: https://sitn.hms.harvard.edu/flash/2017/history-artificial-intelligence/\n",
      "Trying: https://www.technologyreview.com/topic/artificial-intelligence/\n",
      "Trying: https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained\n",
      "Trying: https://www.law.cornell.edu/wex/artificial_intelligence_(ai)\n",
      "Trying: https://www.newscientist.com/definition/artificial-intelligence-ai/\n",
      "Error: HTTPSConnectionPool(host='www.datarobot.com', port=443): Max retries exceeded with url: /wiki/artificial-intelligence/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001FCA9AA23E0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "SSL certificate verification failed for: https://www.datarobot.com/wiki/artificial-intelligence/\n",
      "Trying: https://techcrunch.com/2023/06/28/age-of-ai-everything-you-need-to-know-about-artificial-intelligence/\n",
      "Trying: https://www.nibib.nih.gov/science-education/science-topics/artificial-intelligence-ai\n",
      "Error: HTTPSConnectionPool(host='www.spiceworks.com', port=443): Max retries exceeded with url: /tech/artificial-intelligence/articles/what-is-ai/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001FCAB6F0D60>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "SSL certificate verification failed for: https://www.spiceworks.com/tech/artificial-intelligence/articles/what-is-ai/\n",
      "Trying: https://towardsdatascience.com/advantages-and-disadvantages-of-artificial-intelligence-182a5ef6588c\n",
      "Trying: https://www.opendatasoft.com/en/glossary/artificial-intelligence-ai/\n",
      "Trying: https://www.tableau.com/data-insights/ai/history\n",
      "Trying: https://www.energy.gov/science/doe-explainsartificial-intelligence\n",
      "Trying: https://www.lifewire.com/what-is-artificial-intelligence-5119206\n",
      "Error: HTTPSConnectionPool(host='www.eweek.com', port=443): Max retries exceeded with url: /artificial-intelligence/what-is-artificial-intelligence/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001FCA90C6560>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "SSL certificate verification failed for: https://www.eweek.com/artificial-intelligence/what-is-artificial-intelligence/\n",
      "Error: HTTPSConnectionPool(host='www.microfocus.com', port=443): Max retries exceeded with url: /en-us/what-is/artificial-intelligence (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001FCA90C4190>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "SSL certificate verification failed for: https://www.microfocus.com/en-us/what-is/artificial-intelligence\n",
      "Trying: https://science.howstuffworks.com/artificial-intelligence.htm\n",
      "Error: HTTPSConnectionPool(host='www.earthdata.nasa.gov', port=443): Max retries exceeded with url: /technology/artificial-intelligence-ai (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001FCA8D210C0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "SSL certificate verification failed for: https://www.earthdata.nasa.gov/technology/artificial-intelligence-ai\n",
      "Trying: https://www.sciencedirect.com/topics/social-sciences/artificial-intelligence\n",
      "Error: HTTPSConnectionPool(host='www.gao.gov', port=443): Max retries exceeded with url: /artificial-intelligence (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001FCABE0B730>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "SSL certificate verification failed for: https://www.gao.gov/artificial-intelligence\n",
      "Trying: https://ai.engineering.columbia.edu/ai-vs-machine-learning/\n",
      "Grabbed search results\n"
     ]
    }
   ],
   "source": [
    "#Working implementation\n",
    "\n",
    "session = requests.Session()\n",
    "retry = Retry(connect=2, backoff_factor=0.5)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)\n",
    "# Define the search query and retrieve search results\n",
    "search_query = input(\"What would you like to search up?\")\n",
    "search_engine_url = \"https://www.google.com/search?q=\"\n",
    "\n",
    "# Set headers to mimic a browser request\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Number of search result pages to retrieve (each page typically has 10 results)\n",
    "num_pages = 5\n",
    "\n",
    "search_results = []\n",
    "\n",
    "def verify_ssl_certificate(url):\n",
    "    try:\n",
    "        response = session.get(url, verify=True, headers=headers)\n",
    "        return True\n",
    "    except requests.exceptions.SSLError:\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return False\n",
    "\n",
    "for page in range(num_pages):\n",
    "    # Calculate the start index for the current page\n",
    "    start_index = page * 10\n",
    "\n",
    "    try:\n",
    "        # Make a GET request to retrieve the search result page\n",
    "        response = session.get(search_engine_url + search_query + f\"&start={start_index}\", headers=headers)\n",
    "        response.raise_for_status()  # Raise an exception for non-2xx status codes\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error occurred for page\", page+1)\n",
    "        print(\"Exception:\", e)\n",
    "        continue\n",
    "\n",
    "    # Parse and extract information from the search result page\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    for result in soup.select(\"div.g\"):\n",
    "        title_element = result.select_one(\"h3\")\n",
    "        if title_element:\n",
    "            title = title_element.get_text()\n",
    "            url_element = result.find(\"a\")\n",
    "            if url_element:\n",
    "                url = url_element[\"href\"]\n",
    "                parsed_url = urlparse(url)\n",
    "                if parsed_url.scheme == \"\":\n",
    "                    # Relative URL, convert it to absolute URL\n",
    "                    base_url = response.url\n",
    "                    url = urljoin(base_url, url)\n",
    "\n",
    "                # Verify SSL certificate before making the GET request\n",
    "                if verify_ssl_certificate(url):\n",
    "                    try:\n",
    "                        print(\"Trying:\", url)\n",
    "                        result_response = session.get(url, headers=headers)\n",
    "                        result_response.raise_for_status()  # Raise an exception for non-2xx status codes\n",
    "                        result_soup = BeautifulSoup(result_response.content, \"html.parser\")\n",
    "                        text = result_soup.get_text()\n",
    "                        text = ' '.join(text.split())\n",
    "                        search_results.append({\"Title\": title, \"URL\": url, \"Text\": text})\n",
    "                    except http.client.IncompleteRead:\n",
    "                        print(\"Error: Incomplete read for:\", url)\n",
    "                        continue\n",
    "                    except Exception as e:\n",
    "                        print(\"Error: Failed to retrieve content for:\", url)\n",
    "                        print(\"Exception:\", e)\n",
    "                        continue\n",
    "\n",
    "                # Make a GET request to the URL of the search result\n",
    "                else:\n",
    "                    print(\"SSL certificate verification failed for:\", url)\n",
    "                    continue\n",
    "                    \n",
    "\n",
    "print(\"Grabbed search results\")\n",
    "\n",
    "# Process the search results as desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ace71d1c-a252-4d3c-a969-7d90840edc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ibm</td>\n",
       "      <td>What is Artificial Intelligence (AI)</td>\n",
       "      <td>https://www.ibm.com/topics/artificial-intellig...</td>\n",
       "      <td>What is Artificial Intelligence (AI) ? | IBM W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>builtin</td>\n",
       "      <td>Artificial Intelligence (AI): What Is AI and H...</td>\n",
       "      <td>https://builtin.com/artificial-intelligence</td>\n",
       "      <td>Artificial Intelligence (AI): What Is AI and H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>techtarget</td>\n",
       "      <td>What is artificial intelligence (AI)? - AI def...</td>\n",
       "      <td>https://www.techtarget.com/searchenterpriseai/...</td>\n",
       "      <td>What is artificial intelligence (AI)? - AI def...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oracle</td>\n",
       "      <td>What Is AI? Learn About Artificial Intelligence</td>\n",
       "      <td>https://www.oracle.com/artificial-intelligence...</td>\n",
       "      <td>What is Artificial Intelligence (AI)? | Oracle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brookings</td>\n",
       "      <td>What is artificial intelligence?</td>\n",
       "      <td>https://www.brookings.edu/articles/what-is-art...</td>\n",
       "      <td>What is artificial intelligence? | Brookings E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Domain                                              Title  \\\n",
       "0         ibm               What is Artificial Intelligence (AI)   \n",
       "1     builtin  Artificial Intelligence (AI): What Is AI and H...   \n",
       "2  techtarget  What is artificial intelligence (AI)? - AI def...   \n",
       "3      oracle    What Is AI? Learn About Artificial Intelligence   \n",
       "4   brookings                   What is artificial intelligence?   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.ibm.com/topics/artificial-intellig...   \n",
       "1        https://builtin.com/artificial-intelligence   \n",
       "2  https://www.techtarget.com/searchenterpriseai/...   \n",
       "3  https://www.oracle.com/artificial-intelligence...   \n",
       "4  https://www.brookings.edu/articles/what-is-art...   \n",
       "\n",
       "                                                Text  \n",
       "0  What is Artificial Intelligence (AI) ? | IBM W...  \n",
       "1  Artificial Intelligence (AI): What Is AI and H...  \n",
       "2  What is artificial intelligence (AI)? - AI def...  \n",
       "3  What is Artificial Intelligence (AI)? | Oracle...  \n",
       "4  What is artificial intelligence? | Brookings E...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(search_results)\n",
    "df_bart = pd.DataFrame(search_results)\n",
    "\n",
    "# Extract domain names from URLs and set as the index for the dataframe\n",
    "tld_pattern = re.compile(r'\\.[a-zA-Z]+$')\n",
    "df['Domain'] = df['URL'].apply(lambda url: re.sub(tld_pattern, '', urlparse(url).netloc.replace(\"www.\", \"\")))\n",
    "df.insert(0, 'Domain', df.pop('Domain'))\n",
    "\n",
    "df_bart['Domain'] = df_bart['URL'].apply(lambda url: re.sub(tld_pattern, '', urlparse(url).netloc.replace(\"www.\", \"\")))\n",
    "df_bart.insert(0, 'Domain', df_bart.pop('Domain'))\n",
    "#Handles the \"Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER\" exception\n",
    "df_bart['Text'] = df_bart['Text'].str.replace('\\ufffd', '')\n",
    "\n",
    "#unfiltered dataframe\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3caa3ab-5338-4946-9731-efa2f83cc71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\") #english filler words\n",
    "\n",
    "def preprocess(text):\n",
    "    '''\n",
    "    Input a text block and filter out unneeded characters\n",
    "    returns a filtered text block in the form of a str\n",
    "    Function filters whitespace, numbers, special characters, stopwords; handles case normalization \n",
    "    '''\n",
    "    # Remove special characters and numbers\n",
    "    cleaned_text = re.sub(r\"[^a-zA-Z]+\", \" \", text)\n",
    "    \n",
    "    # Convert to lowercase and split into words\n",
    "    words = cleaned_text.lower().split()\n",
    "    \n",
    "    # Remove stop words and single-character words\n",
    "    filtered_words = [word for word in words if word not in stop_words and len(word) > 1]\n",
    "    lemmatized_text = \" \".join([WordNetLemmatizer().lemmatize(word) for word in filtered_words])\n",
    "    \n",
    "    return lemmatized_text\n",
    "\n",
    "def bart_preprocess(text):\n",
    "\n",
    "    words = text.split()\n",
    "    lemmatized_text = \" \".join([WordNetLemmatizer().lemmatize(word) for word in words])\n",
    "\n",
    "    return lemmatized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e28f1150-3f91-4e37-933b-2250302cbfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of unfiltered text:  14820\n",
      "length of filtered text:  10955\n"
     ]
    }
   ],
   "source": [
    "example = df[\"Text\"][0]\n",
    "processed_example = preprocess(example)\n",
    "\n",
    "print(\"length of unfiltered text: \", len(example))\n",
    "print(\"length of filtered text: \", len(processed_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4372b92-65c2-4d2c-b446-70f1291fd72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Properly using the apply() function onto a pandas column\n",
    "#removes both filler words and special characters\n",
    "df[\"Text\"] = df[\"Text\"].apply(preprocess)\n",
    "df_bart[\"Text\"] = df_bart[\"Text\"].apply(bart_preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e247526b-2b89-42c3-ac86-50cdca58d322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10955\n"
     ]
    }
   ],
   "source": [
    "print(len(df[\"Text\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abbe60f9-c954-4d21-af98-91cdee578452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artificial intelligence ai ibm artificial intelligence ai artificial intelligence leverage computer machine mimic problem solving decision making capability human mind explore watsonx sign ai update artificial intelligence number definition artificial intelligence ai surfaced last decade john mccarthy offer following definition paper pdf kb link resides outside ibm science engineering making intelligent machine especially intelligent computer program related similar task using computer understand human intelligence ai confine method biologically observable however decade definition birth artificial intelligence conversation denoted alan turing seminal work computing machinery intelligence pdf kb link resides outside ibm published paper turing often referred father computer science asks following question machine think offer test famously known turing test human interrogator would try distinguish computer human text response test undergone much scrutiny since publish remains important part history ai well ongoing concept within philosophy utilizes idea around linguistics stuart russell peter norvig proceeded publish artificial intelligence modern approach link resides outside ibm becoming one leading textbook study ai delve four potential goal definition ai differentiates computer system basis rationality thinking v acting human approach system think like human system act like human ideal approach system think rationally system act rationally alan turing definition would fallen category system act like human simplest form artificial intelligence field combine computer science robust datasets enable problem solving also encompasses sub field machine learning deep learning frequently mentioned conjunction artificial intelligence discipline comprised ai algorithm seek create expert system make prediction classification based input data year artificial intelligence gone many cycle hype even skeptic release openai chatgpt seems mark turning point last time generative ai loomed large breakthrough computer vision leap forward natural language processing language generative model also learn grammar software code molecule natural image variety data type application technology growing every day starting explore possibility hype around use ai business take conversation around ethic become critically important read ibm stand within conversation around ai ethic read ibm point view ai learn thrive new era ai trust confidence mb read meet watsonx ai magic quadrant enterprise conversational ai platform ibm watson orchestrate ibm watson assistant type artificial intelligence weak ai v strong ai weak ai also called narrow ai artificial narrow intelligence ani ai trained focused perform specific task weak ai drive ai surround u today narrow might accurate descriptor type ai anything weak enables robust application apple siri amazon alexa ibm watson autonomous vehicle strong ai made artificial general intelligence agi artificial super intelligence asi artificial general intelligence agi general ai theoretical form ai machine would intelligence equaled human would self aware consciousness ability solve problem learn plan future artificial super intelligence asi also known superintelligence would surpass intelligence ability human brain strong ai still entirely theoretical practical example use today mean ai researcher also exploring development meantime best example asi might science fiction hal superhuman rogue computer assistant space odyssey deep learning v machine learning since deep learning machine learning tend used interchangeably worth noting nuance two mentioned deep learning machine learning sub field artificial intelligence deep learning actually sub field machine learning deep learning actually comprised neural network deep deep learning refers neural network comprised three layer would inclusive input output considered deep learning algorithm generally represented using diagram way deep learning machine learning differ algorithm learns deep learning automates much feature extraction piece process eliminating manual human intervention required enabling use larger data set think deep learning scalable machine learning lex fridman noted mit lecture classical non deep machine learning dependent human intervention learn human expert determine hierarchy feature understand difference data input usually requiring structured data learn deep machine learning leverage labeled datasets also known supervised learning inform algorithm necessarily require labeled dataset ingest unstructured data raw form text image automatically determine hierarchy feature distinguish different category data one another unlike machine learning require human intervention process data allowing u scale machine learning interesting way rise generative model generative ai refers deep learning model take raw data say wikipedia collected work rembrandt learn generate statistically probable output prompted high level generative model encode simplified representation training data draw create new work similar identical original data generative model used year statistic analyze numerical data rise deep learning however made possible extend image speech complex data type among first class model achieve cross feat variational autoencoders vaes introduced vaes first deep learning model widely used generating realistic image speech vaes opened floodgate deep generative modeling making model easier scale said akash srivastava expert generative ai mit ibm watson ai lab much think today generative ai started early example model like gpt bert dall shown possible future model trained broad set unlabeled data used different task minimal fine tuning system execute specific task single domain giving way broad ai learns generally work across domain problem foundation model trained large unlabeled datasets fine tuned array application driving shift come generative ai predicted foundation model dramatically accelerate ai adoption enterprise reducing labeling requirement make much easier business dive highly accurate efficient ai driven automation enable mean far company able deploy ai wider range mission critical situation ibm hope power foundation model eventually brought every enterprise frictionless hybrid cloud environment artificial intelligence application numerous real world application ai system today common use case speech recognition also known automatic speech recognition asr computer speech recognition speech text capability us natural language processing nlp process human speech written format many mobile device incorporate speech recognition system conduct voice search siri provide accessibility around texting customer service online virtual agent replacing human agent along customer journey answer frequently asked question faq around topic like shipping provide personalized advice cross selling product suggesting size user changing way think customer engagement across website social medium platform example include messaging bot commerce site virtual agent messaging apps slack facebook messenger task usually done virtual assistant voice assistant computer vision ai technology enables computer system derive meaningful information digital image video visual input based input take action ability provide recommendation distinguishes image recognition task powered convolutional neural network computer vision application within photo tagging social medium radiology imaging healthcare self driving car within automotive industry recommendation engine using past consumption behavior data ai algorithm help discover data trend used develop effective cross selling strategy used make relevant add recommendation customer checkout process online retailer automated stock trading designed optimize stock portfolio ai driven high frequency trading platform make thousand even million trade per day without human intervention history artificial intelligence key date name idea machine think date back ancient greece since advent electronic computing relative topic discussed article important event milestone evolution artificial intelligence include following alan turing publishes computing machinery intelligence paper turing famous breaking nazi enigma code wwii proposes answer question machine think introduces turing test determine computer demonstrate intelligence result intelligence human value turing test debated ever since john mccarthy coin term artificial intelligence first ever ai conference dartmouth college mccarthy would go invent lisp language later year allen newell shaw herbert simon create logic theorist first ever running ai software program frank rosenblatt build mark perceptron first computer based neural network learned though trial error year later marvin minsky seymour papert publish book titled perceptrons becomes landmark work neural network least argument future neural network research project neural network use backpropagation algorithm train become widely used ai application ibm deep blue beat world chess champion garry kasparov chess match rematch ibm watson beat champion ken jennings brad rutter jeopardy baidu minwa supercomputer us special kind deep neural network called convolutional neural network identify categorize image higher rate accuracy average human deepmind alphago program powered deep neural network beat lee sodol world champion go player five game match victory significant given huge number possible move game progress trillion four move later google purchased deepmind reported usd million rise large language model llm chatgpt create enormous change performance ai potential drive enterprise value new generative ai practice deep learning model pre trained vast amount raw unlabeled data related solution artificial intelligence ai solution put ai work business ibm industry leading ai expertise portfolio solution side explore ai solution ai service reinvent critical workflow operation adding ai maximize experience decision making business value explore ai service ai cybersecurity ai changing game cybersecurity analyzing massive quantity risk data speed response time augment resourced security operation explore ai cybersecurity resource book download artificial intelligence ebook discover fresh insight opportunity challenge lesson learned infusing ai business training save digital learning subscription access full catalog online course purchasing individual multi user digital learning subscription today allowing expand skill across range product one low price market research magic quadrant enterprise conversational ai platform ibm recognized leader gartner magic quadrant enterprise conversational ai register report take next step ibm leader advancing ai driven technology enterprise pioneered future machine learning system multiple industry learn ibm watson give enterprise ai tool need transform business system workflow significantly improving automation efficiency explore ai solution'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filtered text for first row entry\n",
    "df[\"Text\"][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e7569cf-2a71-4793-9b9f-521d9f6b8595",
   "metadata": {},
   "source": [
    "# Part 2: EDA, Feature Engineering, and Model Development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58c4ac7a",
   "metadata": {},
   "source": [
    "### Future Optimizations\n",
    "\n",
    "1. Ignore website navigation for websites like (wikipedia, stackoverflow, etc.)\n",
    "\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Research into transformer, BART model, to better understand model set up and how to get highest performance\n",
    "2. Experiment with BART input (lemmatize/not, capitalization, etc.) to find best performance \n",
    "3. Try to implement BART model with recursion as per the drawn diagram \n",
    "4. Research into paralellization of transformer models with HuggingFace \n",
    "\n",
    "### Notes\n",
    "\n",
    "1. To actually make project work, we need to create a few metrics that we can train a DL model on. Maybe, linguistic complexity (formulaic), sentiment analysis, text length, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51ee1b1f-ddd8-4aeb-8ec8-8d72147d7279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 25\n",
      "Validation set size: 7\n",
      "Test set size: 9\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have a DataFrame called 'df' containing your data\n",
    "# Split the data into train and test sets (80% train, 20% test)\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the train data further into train and validation sets (80% train, 20% validation)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the sizes of each dataset\n",
    "print(\"Train set size:\", len(train_data))\n",
    "print(\"Validation set size:\", len(val_data))\n",
    "print(\"Test set size:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba059c5c-9041-4965-9c83-b8bdc0568466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>netapp</td>\n",
       "      <td>What Is Artificial Intelligence or AI and why ...</td>\n",
       "      <td>https://www.netapp.com/artificial-intelligence...</td>\n",
       "      <td>artificial intelligence ai important netapp bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>britannica</td>\n",
       "      <td>Artificial intelligence (AI) | Definition, Exa...</td>\n",
       "      <td>https://www.britannica.com/technology/artifici...</td>\n",
       "      <td>artificial intelligence ai definition example ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mckinsey</td>\n",
       "      <td>What is AI (Artificial Intelligence)?</td>\n",
       "      <td>https://www.mckinsey.com/featured-insights/mck...</td>\n",
       "      <td>ai artificial intelligence mckinsey skip main ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>investopedia</td>\n",
       "      <td>Artificial Intelligence: What It Is and How It...</td>\n",
       "      <td>https://www.investopedia.com/terms/a/artificia...</td>\n",
       "      <td>artificial intelligence used investing stock b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aws.amazon</td>\n",
       "      <td>What is Artificial Intelligence (AI)? — Amazon...</td>\n",
       "      <td>https://aws.amazon.com/machine-learning/what-i...</td>\n",
       "      <td>artificial intelligence ai amazon web service ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>techopedia</td>\n",
       "      <td>What is Artificial Intelligence (AI)?</td>\n",
       "      <td>https://www.techopedia.com/definition/190/arti...</td>\n",
       "      <td>artificial intelligence ai definition techoped...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zdnet</td>\n",
       "      <td>What is AI? Everything to know about artificia...</td>\n",
       "      <td>https://www.zdnet.com/article/what-is-ai-heres...</td>\n",
       "      <td>ai everything know artificial intelligence zdn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>technologyreview</td>\n",
       "      <td>Artificial intelligence | MIT Technology Review</td>\n",
       "      <td>https://www.technologyreview.com/topic/artific...</td>\n",
       "      <td>artificial intelligence mit technology review ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>towardsdatascience</td>\n",
       "      <td>Advantages and Disadvantages of Artificial Int...</td>\n",
       "      <td>https://towardsdatascience.com/advantages-and-...</td>\n",
       "      <td>advantage disadvantage artificial intelligence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pewresearch</td>\n",
       "      <td>Artificial Intelligence and the Future of Humans</td>\n",
       "      <td>https://www.pewresearch.org/internet/2018/12/1...</td>\n",
       "      <td>artificial intelligence future human pew resea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mygreatlearning</td>\n",
       "      <td>What is Artificial Intelligence ( AI) in 2023?</td>\n",
       "      <td>https://www.mygreatlearning.com/blog/what-is-a...</td>\n",
       "      <td>artificial intelligence ai great learning skip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>state</td>\n",
       "      <td>Artificial Intelligence (AI) - United States D...</td>\n",
       "      <td>https://www.state.gov/artificial-intelligence/</td>\n",
       "      <td>artificial intelligence ai united state depart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gartner</td>\n",
       "      <td>What Is Artificial Intelligence (AI)</td>\n",
       "      <td>https://www.gartner.com/en/topics/artificial-i...</td>\n",
       "      <td>artificial intelligence ai gartner account con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>energy</td>\n",
       "      <td>DOE Explains...Artificial Intelligence</td>\n",
       "      <td>https://www.energy.gov/science/doe-explainsart...</td>\n",
       "      <td>doe explains artificial intelligence departmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>simplilearn</td>\n",
       "      <td>What is Artificial Intelligence: Types, Histor...</td>\n",
       "      <td>https://www.simplilearn.com/tutorials/artifici...</td>\n",
       "      <td>artificial intelligence type history future ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nist</td>\n",
       "      <td>Artificial intelligence | NIST</td>\n",
       "      <td>https://www.nist.gov/artificial-intelligence</td>\n",
       "      <td>artificial intelligence nist skip main content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>techcrunch</td>\n",
       "      <td>Age of AI: Everything you need to know about a...</td>\n",
       "      <td>https://techcrunch.com/2023/06/28/age-of-ai-ev...</td>\n",
       "      <td>age ai everything need know artificial intelli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>science.howstuffworks</td>\n",
       "      <td>How Artificial Intelligence Is Totally Changin...</td>\n",
       "      <td>https://science.howstuffworks.com/artificial-i...</td>\n",
       "      <td>artificial intelligence totally changing every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>oracle</td>\n",
       "      <td>What Is AI? Learn About Artificial Intelligence</td>\n",
       "      <td>https://www.oracle.com/artificial-intelligence...</td>\n",
       "      <td>artificial intelligence ai oracle accessibilit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>What is artificial intelligence? AI glossary o...</td>\n",
       "      <td>https://www.washingtonpost.com/technology/2023...</td>\n",
       "      <td>artificial intelligence ai glossary term know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ibm</td>\n",
       "      <td>What is Artificial Intelligence (AI)</td>\n",
       "      <td>https://www.ibm.com/topics/artificial-intellig...</td>\n",
       "      <td>artificial intelligence ai ibm artificial inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>builtin</td>\n",
       "      <td>Artificial Intelligence (AI): What Is AI and H...</td>\n",
       "      <td>https://builtin.com/artificial-intelligence</td>\n",
       "      <td>artificial intelligence ai ai work built skip ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sas</td>\n",
       "      <td>Artificial Intelligence (AI): What it is and w...</td>\n",
       "      <td>https://www.sas.com/en_us/insights/analytics/w...</td>\n",
       "      <td>artificial intelligence ai matter sa skip main...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lifewire</td>\n",
       "      <td>What Is Artificial Intelligence?</td>\n",
       "      <td>https://www.lifewire.com/what-is-artificial-in...</td>\n",
       "      <td>artificial intelligence ga regular menu lifewi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nibib.nih</td>\n",
       "      <td>Artificial Intelligence (AI)</td>\n",
       "      <td>https://www.nibib.nih.gov/science-education/sc...</td>\n",
       "      <td>artificial intelligence ai skip main content d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Domain                                              Title  \\\n",
       "0                  netapp  What Is Artificial Intelligence or AI and why ...   \n",
       "1              britannica  Artificial intelligence (AI) | Definition, Exa...   \n",
       "2                mckinsey              What is AI (Artificial Intelligence)?   \n",
       "3            investopedia  Artificial Intelligence: What It Is and How It...   \n",
       "4              aws.amazon  What is Artificial Intelligence (AI)? — Amazon...   \n",
       "5              techopedia              What is Artificial Intelligence (AI)?   \n",
       "6                   zdnet  What is AI? Everything to know about artificia...   \n",
       "7        technologyreview    Artificial intelligence | MIT Technology Review   \n",
       "8      towardsdatascience  Advantages and Disadvantages of Artificial Int...   \n",
       "9             pewresearch   Artificial Intelligence and the Future of Humans   \n",
       "10        mygreatlearning     What is Artificial Intelligence ( AI) in 2023?   \n",
       "11                  state  Artificial Intelligence (AI) - United States D...   \n",
       "12                gartner               What Is Artificial Intelligence (AI)   \n",
       "13                 energy             DOE Explains...Artificial Intelligence   \n",
       "14            simplilearn  What is Artificial Intelligence: Types, Histor...   \n",
       "15                   nist                     Artificial intelligence | NIST   \n",
       "16             techcrunch  Age of AI: Everything you need to know about a...   \n",
       "17  science.howstuffworks  How Artificial Intelligence Is Totally Changin...   \n",
       "18                 oracle    What Is AI? Learn About Artificial Intelligence   \n",
       "19         washingtonpost  What is artificial intelligence? AI glossary o...   \n",
       "20                    ibm               What is Artificial Intelligence (AI)   \n",
       "21                builtin  Artificial Intelligence (AI): What Is AI and H...   \n",
       "22                    sas  Artificial Intelligence (AI): What it is and w...   \n",
       "23               lifewire                   What Is Artificial Intelligence?   \n",
       "24              nibib.nih                       Artificial Intelligence (AI)   \n",
       "\n",
       "                                                  URL  \\\n",
       "0   https://www.netapp.com/artificial-intelligence...   \n",
       "1   https://www.britannica.com/technology/artifici...   \n",
       "2   https://www.mckinsey.com/featured-insights/mck...   \n",
       "3   https://www.investopedia.com/terms/a/artificia...   \n",
       "4   https://aws.amazon.com/machine-learning/what-i...   \n",
       "5   https://www.techopedia.com/definition/190/arti...   \n",
       "6   https://www.zdnet.com/article/what-is-ai-heres...   \n",
       "7   https://www.technologyreview.com/topic/artific...   \n",
       "8   https://towardsdatascience.com/advantages-and-...   \n",
       "9   https://www.pewresearch.org/internet/2018/12/1...   \n",
       "10  https://www.mygreatlearning.com/blog/what-is-a...   \n",
       "11     https://www.state.gov/artificial-intelligence/   \n",
       "12  https://www.gartner.com/en/topics/artificial-i...   \n",
       "13  https://www.energy.gov/science/doe-explainsart...   \n",
       "14  https://www.simplilearn.com/tutorials/artifici...   \n",
       "15       https://www.nist.gov/artificial-intelligence   \n",
       "16  https://techcrunch.com/2023/06/28/age-of-ai-ev...   \n",
       "17  https://science.howstuffworks.com/artificial-i...   \n",
       "18  https://www.oracle.com/artificial-intelligence...   \n",
       "19  https://www.washingtonpost.com/technology/2023...   \n",
       "20  https://www.ibm.com/topics/artificial-intellig...   \n",
       "21        https://builtin.com/artificial-intelligence   \n",
       "22  https://www.sas.com/en_us/insights/analytics/w...   \n",
       "23  https://www.lifewire.com/what-is-artificial-in...   \n",
       "24  https://www.nibib.nih.gov/science-education/sc...   \n",
       "\n",
       "                                                 Text  \n",
       "0   artificial intelligence ai important netapp bl...  \n",
       "1   artificial intelligence ai definition example ...  \n",
       "2   ai artificial intelligence mckinsey skip main ...  \n",
       "3   artificial intelligence used investing stock b...  \n",
       "4   artificial intelligence ai amazon web service ...  \n",
       "5   artificial intelligence ai definition techoped...  \n",
       "6   ai everything know artificial intelligence zdn...  \n",
       "7   artificial intelligence mit technology review ...  \n",
       "8   advantage disadvantage artificial intelligence...  \n",
       "9   artificial intelligence future human pew resea...  \n",
       "10  artificial intelligence ai great learning skip...  \n",
       "11  artificial intelligence ai united state depart...  \n",
       "12  artificial intelligence ai gartner account con...  \n",
       "13  doe explains artificial intelligence departmen...  \n",
       "14  artificial intelligence type history future ed...  \n",
       "15  artificial intelligence nist skip main content...  \n",
       "16  age ai everything need know artificial intelli...  \n",
       "17  artificial intelligence totally changing every...  \n",
       "18  artificial intelligence ai oracle accessibilit...  \n",
       "19  artificial intelligence ai glossary term know ...  \n",
       "20  artificial intelligence ai ibm artificial inte...  \n",
       "21  artificial intelligence ai ai work built skip ...  \n",
       "22  artificial intelligence ai matter sa skip main...  \n",
       "23  artificial intelligence ga regular menu lifewi...  \n",
       "24  artificial intelligence ai skip main content d...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.reset_index().drop([\"index\"], axis = 1)\n",
    "val_data.reset_index().drop([\"index\"], axis = 1)\n",
    "train_data.reset_index().drop([\"index\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f9d9f55-1489-4477-a4cb-1201133ff0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Bart\n",
    "# !pip install transformers\n",
    "# !pip install torch\n",
    "from transformers import BartForConditionalGeneration, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da42f2ca-e71a-4bb0-b91b-3fa9cc51d822",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BartForConditionalGeneration' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m BartForConditionalGeneration\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mfacebook/bart-large-cnn\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mfacebook/bart-large-cnn\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BartForConditionalGeneration' is not defined"
     ]
    }
   ],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4027035e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41231"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(df_bart[\"Text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc0650de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tokenizer([df_bart[\"Text\"][2]],max_length = 1024,return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f50aef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is RGB Color? – Nix Sensor Ltd – NIX Sensor Ltd Skip to content BRAND NEW Nix Mini 3'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_ids = model.generate(inputs[\"input_ids\"], num_beams=1, min_length=0, max_length=30)\n",
    "tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fe86c91",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Max retries exceeded with url: /allenai/led-large-16384-arxiv/b5a5e37ba3760d17033acb8079d62c561295f549d0b69336b1fbb894b549d4c5?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1688792694&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL2FsbGVuYWkvbGVkLWxhcmdlLTE2Mzg0LWFyeGl2L2I1YTVlMzdiYTM3NjBkMTcwMzNhY2I4MDc5ZDYyYzU2MTI5NWY1NDlkMGI2OTMzNmIxZmJiODk0YjU0OWQ0YzU~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjg4NzkyNjk0fX19XX0_&Signature=SdDRoCiqsisV4QLDrUBLQMg2UAiANoXA5qPRsYXq20EtmL1Osr7D~fBirWcWti0KXJKNlov0j94akIky5z1IFRy6SkG5wnxj2jvV6vCwniv4og3EXp5GJ5~DOkySoq5zZvpzhFCd0DfV7lEx0Ju63-aot1Zo~XXLBeg-5BBO24qL0G3gSE65PwFRrI2OM0xFk7NgHtgEXhzABhbcWfhv6E~xenjGu3~6Gl8MB6mJcOvqsKEA2HYR4~~G-ep1r5xo9SDHN8oyvysO5VXrE9nw4Pg5ukjep-vQzlYJmNA-2UESicAIg3Dq02xaRcB2umrHMsUTKQPWuCdC0YDBY4Xstg__&Key-Pair-Id=KVTP0A1DKRTAX (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001FCC0FB1B10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dns_host, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mport), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\urllib3\\util\\connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m six\u001b[39m.\u001b[39mraise_from(\n\u001b[0;32m     69\u001b[0m         LocationParseError(\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, label empty or too long\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m host), \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     )\n\u001b[1;32m---> 72\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, socket\u001b[39m.\u001b[39;49mSOCK_STREAM):\n\u001b[0;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    954\u001b[0m addrlist \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 955\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m _socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, \u001b[39mtype\u001b[39;49m, proto, flags):\n\u001b[0;32m    956\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\urllib3\\connectionpool.py:403\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    404\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    405\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\urllib3\\connectionpool.py:1053\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1053\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1055\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\urllib3\\connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[39m# Add certificate verification\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[0;32m    364\u001b[0m     hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39mexcept\u001b[39;00m SocketError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to establish a new connection: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x000001FCC0FB1B10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\requests\\adapters.py:487\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 487\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    488\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    489\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    490\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    491\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    492\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    496\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    497\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    498\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    499\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\urllib3\\connectionpool.py:798\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    796\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m--> 798\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    799\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    801\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Max retries exceeded with url: /allenai/led-large-16384-arxiv/b5a5e37ba3760d17033acb8079d62c561295f549d0b69336b1fbb894b549d4c5?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1688792694&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL2FsbGVuYWkvbGVkLWxhcmdlLTE2Mzg0LWFyeGl2L2I1YTVlMzdiYTM3NjBkMTcwMzNhY2I4MDc5ZDYyYzU2MTI5NWY1NDlkMGI2OTMzNmIxZmJiODk0YjU0OWQ0YzU~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjg4NzkyNjk0fX19XX0_&Signature=SdDRoCiqsisV4QLDrUBLQMg2UAiANoXA5qPRsYXq20EtmL1Osr7D~fBirWcWti0KXJKNlov0j94akIky5z1IFRy6SkG5wnxj2jvV6vCwniv4og3EXp5GJ5~DOkySoq5zZvpzhFCd0DfV7lEx0Ju63-aot1Zo~XXLBeg-5BBO24qL0G3gSE65PwFRrI2OM0xFk7NgHtgEXhzABhbcWfhv6E~xenjGu3~6Gl8MB6mJcOvqsKEA2HYR4~~G-ep1r5xo9SDHN8oyvysO5VXrE9nw4Pg5ukjep-vQzlYJmNA-2UESicAIg3Dq02xaRcB2umrHMsUTKQPWuCdC0YDBY4Xstg__&Key-Pair-Id=KVTP0A1DKRTAX (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001FCC0FB1B10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer, LEDForConditionalGeneration\n\u001b[0;32m      3\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m model \u001b[39m=\u001b[39m LEDForConditionalGeneration\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mallenai/led-large-16384-arxiv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      5\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mallenai/led-large-16384-arxiv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m inputs \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode(df_bart[\u001b[39m\"\u001b[39m\u001b[39mText\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m], return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\transformers\\modeling_utils.py:2432\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2417\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2418\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m   2419\u001b[0m     cached_file_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m   2420\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcache_dir\u001b[39m\u001b[39m\"\u001b[39m: cache_dir,\n\u001b[0;32m   2421\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mforce_download\u001b[39m\u001b[39m\"\u001b[39m: force_download,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2430\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m: commit_hash,\n\u001b[0;32m   2431\u001b[0m     }\n\u001b[1;32m-> 2432\u001b[0m     resolved_archive_file \u001b[39m=\u001b[39m cached_file(pretrained_model_name_or_path, filename, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcached_file_kwargs)\n\u001b[0;32m   2434\u001b[0m     \u001b[39m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[0;32m   2435\u001b[0m     \u001b[39m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[0;32m   2436\u001b[0m     \u001b[39mif\u001b[39;00m resolved_archive_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m filename \u001b[39m==\u001b[39m _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[0;32m   2437\u001b[0m         \u001b[39m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\transformers\\utils\\hub.py:417\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[0;32m    414\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 417\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[0;32m    418\u001b[0m         path_or_repo_id,\n\u001b[0;32m    419\u001b[0m         filename,\n\u001b[0;32m    420\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[0;32m    421\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[0;32m    422\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m    423\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    424\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m    425\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    426\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    427\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    428\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m    429\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    430\u001b[0m     )\n\u001b[0;32m    432\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[0;32m    433\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    434\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlisted on \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    437\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    438\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\huggingface_hub\\file_download.py:1364\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[0;32m   1361\u001b[0m \u001b[39mwith\u001b[39;00m temp_file_manager() \u001b[39mas\u001b[39;00m temp_file:\n\u001b[0;32m   1362\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mdownloading \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url, temp_file\u001b[39m.\u001b[39mname)\n\u001b[1;32m-> 1364\u001b[0m     http_get(\n\u001b[0;32m   1365\u001b[0m         url_to_download,\n\u001b[0;32m   1366\u001b[0m         temp_file,\n\u001b[0;32m   1367\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   1368\u001b[0m         resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[0;32m   1369\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m   1370\u001b[0m         expected_size\u001b[39m=\u001b[39;49mexpected_size,\n\u001b[0;32m   1371\u001b[0m     )\n\u001b[0;32m   1373\u001b[0m \u001b[39mif\u001b[39;00m local_dir \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mblob_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\huggingface_hub\\file_download.py:505\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[39mif\u001b[39;00m resume_size \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    503\u001b[0m     headers[\u001b[39m\"\u001b[39m\u001b[39mRange\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbytes=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (resume_size,)\n\u001b[1;32m--> 505\u001b[0m r \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[0;32m    506\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    507\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    508\u001b[0m     stream\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    509\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    510\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    511\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    512\u001b[0m     max_retries\u001b[39m=\u001b[39;49mmax_retries,\n\u001b[0;32m    513\u001b[0m )\n\u001b[0;32m    514\u001b[0m hf_raise_for_status(r)\n\u001b[0;32m    515\u001b[0m content_length \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mContent-Length\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\huggingface_hub\\file_download.py:442\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n\u001b[0;32m    441\u001b[0m \u001b[39m# 3. Exponential backoff\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m \u001b[39mreturn\u001b[39;00m http_backoff(\n\u001b[0;32m    443\u001b[0m     method\u001b[39m=\u001b[39mmethod,\n\u001b[0;32m    444\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[0;32m    445\u001b[0m     max_retries\u001b[39m=\u001b[39mmax_retries,\n\u001b[0;32m    446\u001b[0m     base_wait_time\u001b[39m=\u001b[39mbase_wait_time,\n\u001b[0;32m    447\u001b[0m     max_wait_time\u001b[39m=\u001b[39mmax_wait_time,\n\u001b[0;32m    448\u001b[0m     retry_on_exceptions\u001b[39m=\u001b[39m(ConnectTimeout, ProxyError),\n\u001b[0;32m    449\u001b[0m     retry_on_status_codes\u001b[39m=\u001b[39m(),\n\u001b[0;32m    450\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[0;32m    451\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    452\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:212\u001b[0m, in \u001b[0;36mhttp_backoff\u001b[1;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mseek(io_obj_initial_pos)\n\u001b[0;32m    211\u001b[0m \u001b[39m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m response \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    213\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m retry_on_status_codes:\n\u001b[0;32m    214\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\William Zhang\\.conda\\envs\\search_sense\\lib\\site-packages\\requests\\adapters.py:520\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    517\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m--> 520\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    522\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    523\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Max retries exceeded with url: /allenai/led-large-16384-arxiv/b5a5e37ba3760d17033acb8079d62c561295f549d0b69336b1fbb894b549d4c5?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1688792694&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL2FsbGVuYWkvbGVkLWxhcmdlLTE2Mzg0LWFyeGl2L2I1YTVlMzdiYTM3NjBkMTcwMzNhY2I4MDc5ZDYyYzU2MTI5NWY1NDlkMGI2OTMzNmIxZmJiODk0YjU0OWQ0YzU~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjg4NzkyNjk0fX19XX0_&Signature=SdDRoCiqsisV4QLDrUBLQMg2UAiANoXA5qPRsYXq20EtmL1Osr7D~fBirWcWti0KXJKNlov0j94akIky5z1IFRy6SkG5wnxj2jvV6vCwniv4og3EXp5GJ5~DOkySoq5zZvpzhFCd0DfV7lEx0Ju63-aot1Zo~XXLBeg-5BBO24qL0G3gSE65PwFRrI2OM0xFk7NgHtgEXhzABhbcWfhv6E~xenjGu3~6Gl8MB6mJcOvqsKEA2HYR4~~G-ep1r5xo9SDHN8oyvysO5VXrE9nw4Pg5ukjep-vQzlYJmNA-2UESicAIg3Dq02xaRcB2umrHMsUTKQPWuCdC0YDBY4Xstg__&Key-Pair-Id=KVTP0A1DKRTAX (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001FCC0FB1B10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, LEDForConditionalGeneration\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = LEDForConditionalGeneration.from_pretrained(\"allenai/led-large-16384-arxiv\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-large-16384-arxiv\")\n",
    "\n",
    "\n",
    "inputs = tokenizer.encode(df_bart[\"Text\"][0], return_tensors=\"pt\")\n",
    "\n",
    "global_attention_mask = torch.zeros_like(inputs)\n",
    "global_attention_mask[:, 0] = 1\n",
    "\n",
    "model = model.to(device)\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "summary_ids = model.generate(inputs, global_attention_mask=global_attention_mask, num_beams=3, max_length=32)\n",
    "print(tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
